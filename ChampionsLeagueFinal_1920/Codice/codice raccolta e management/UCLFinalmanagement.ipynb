{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongo', 27017, username='admin', password='DataMan2019!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=client.UCLFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trova ed elimina i duplicati cercando per tweet id con questa funzione inserita da console mongo:\n",
    "\n",
    "db.partita.aggregate([\n",
    " {\n",
    "     \"$group\": {\n",
    "         _id: { id : \"$id\"},\n",
    "         dups: { $addToSet: \"$_id\" } ,\n",
    "         count: { $sum : 1 } \n",
    "     }\n",
    " },\n",
    " {\n",
    "     \"$match\": {\n",
    "         count: { \"$gt\": 1 }\n",
    "     }\n",
    " }\n",
    "],{ allowDiskUse:true}).forEach(function(doc) {\n",
    "   doc.dups.shift();\n",
    "   db.partita.remove({\n",
    "       _id: {$in: doc.dups}\n",
    "   });\n",
    "} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index response: timestamp_1\n"
     ]
    }
   ],
   "source": [
    "#indexing, creiamo alcuni indici per facilitare la ricerca nei campi che utilizziamo per la ricerca. E' buona norma applicare al massimo 2 indici per collezione:\n",
    "\n",
    "resp = db.partita.create_index([ (\"timestamp\", 1) ])\n",
    "print (\"index response:\", resp) #non cambia il nome della variabile\n",
    "\n",
    "\n",
    "#facilita la ricerca, creane per diversi campi, quelli pi√π battuti. Il secondo indice, di default √® '_id', fornito da mongo nell'atto dell'immagazzinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758373"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.partita.estimated_document_count()   #numero di tweet nella collezione dopo l'eliminazione dei duplicati (solo 3 duplicati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stat_UCL=pd.read_csv(\"/home/studente/my-data/statistiche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x7f93adb6ee88>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#timestamp to ISODAte, tenendo anche timestamp:\n",
    "db.partita.update_many(\n",
    "   {\"FixedDate\": {\"$exists\": False}},\n",
    "   [{\"$set\":{\n",
    "      \"FixedDate\":{\"$toString\":\"$timestamp\"}\n",
    "  }},\n",
    "  {\"$set\":{\n",
    "      \"NewDate\": {\"$toDate\": \"$FixedDate\"}\n",
    "  }}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5f42a3f3b957f1aa3f18ad40'),\n",
       " 'id': '1297582966332362753',\n",
       " 'user_location': None,\n",
       " 'language': 'ar',\n",
       " 'timestamp': '2020-08-23 19:14:21',\n",
       " 'text': 'RT @realmeSaudi: ‚öΩ ÿ™ŸàŸÇÿπ Ÿàÿßÿ±ÿ®ÿ≠ ÿ¨Ÿáÿßÿ≤ realme C3 ü•≥\\nÿ™ŸàŸÇÿπ ÿßŸÑŸÅÿ±ŸäŸÇ ÿßŸÑÿ±ÿßÿ®ÿ≠ ŸÅŸä ÿßŸÑŸÖÿ®ÿßÿ±ÿßÿ© ÿßŸÑŸäŸàŸÖ  ŸÑŸÅÿ±ÿµÿ© ÿßŸÑŸÅŸàÿ≤ ÿ®ÿ¨Ÿáÿßÿ≤ realme C3 \\nÿ¥ÿ±Ÿàÿ∑ ÿßŸÑŸÖÿ≥ÿßÿ®ŸÇÿ© ÿ®ÿ≥Ÿäÿ∑ÿ© :\\nŸÄ ŸÖ‚Ä¶',\n",
       " 'hashtags': [],\n",
       " 'urls': [],\n",
       " 'user_mentions': [{'screen_name': 'realmeSaudi',\n",
       "   'name': 'realme Saudi | ÿ±ŸäŸÑŸÖŸä ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©',\n",
       "   'id': 1208760012635615237,\n",
       "   'id_str': '1208760012635615237',\n",
       "   'indices': [3, 15]}],\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'is_a_retweet': 'True',\n",
       " 'user_followers': 48,\n",
       " 'FixedDate': '2020-08-23 19:14:21',\n",
       " 'NewDate': datetime.datetime(2020, 8, 23, 19, 14, 21)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.partita.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT COLLEZIONI SUDDIVISE:\n",
    "\n",
    "#PRIMO TEMPO:\n",
    "agg=db.partita.aggregate(\n",
    "   [{'$match':{\"timestamp\":{\"$gte\":\"2020-08-23 21:01:00\",\"$lt\":\"2020-08-23 21:48:00\"}}},\n",
    "     {\n",
    "       '$project':\n",
    "         {\n",
    "             'id':'$id',\n",
    "             'user_location':'$user_location',\n",
    "             'language':'$language',\n",
    "             'timestamp':'$timestamp',\n",
    "             'text':'$text',\n",
    "             'hashtags':'$hashtags',\n",
    "             'urls':'$urls',\n",
    "             'user_mentions':'$user_mentions',\n",
    "             'geo':'$geo',\n",
    "             'coordinates':'$coordinates',\n",
    "             'retweet_count':'$retweet_count',\n",
    "             'retweeted':'$retweeted',\n",
    "             'is_a_retweet':'$is_a_retweet',\n",
    "             'user_followers':'$user_followers',\n",
    "             'minuto_partita': { '$minute': \"$NewDate\" }\n",
    "         }\n",
    "     },\n",
    "       { '$out' :'primo_tempo'}   #out permette di ottenere una collezione nel db di riferimento\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECONDO TEMPO:\n",
    "agg=db.partita.aggregate(\n",
    "   [{'$match':{\"timestamp\":{\"$gte\":\"2020-08-23 22:04:00\",\"$lte\":\"2020-08-23 22:54:00\"}}},\n",
    "     {\n",
    "       '$project':\n",
    "         {\n",
    "             'id':'$id',\n",
    "             'user_location':'$user_location',\n",
    "             'language':'$language',\n",
    "             'timestamp':'$timestamp',\n",
    "             'text':'$text',\n",
    "             'hashtags':'$hashtags',\n",
    "             'urls':'$urls',\n",
    "             'user_mentions':'$user_mentions',\n",
    "             'geo':'$geo',\n",
    "             'coordinates':'$coordinates',\n",
    "             'retweet_count':'$retweet_count',\n",
    "             'retweeted':'$retweeted',\n",
    "             'is_a_retweet':'$is_a_retweet',\n",
    "             'user_followers':'$user_followers',\n",
    "             'minuto_partita': { '$add':[{'$minute': \"$NewDate\"}, 42]} #+45 minuti per entrare in secondo tempo e togliamo 3 per passare da 04 a 01 come pt\n",
    "         }\n",
    "     },\n",
    "       { '$out' :'secondo_tempo'}\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERVALLO:\n",
    "agg=db.partita.aggregate(\n",
    "   [{'$match':{\"timestamp\":{\"$lt\":\"2020-08-23 22:04:00\",\"$gte\":\"2020-08-23 21:48:00\"}}}, #riferimento dell'intervallo\n",
    "     {\n",
    "       '$project':\n",
    "         {\n",
    "             'id':'$id',\n",
    "             'user_location':'$user_location',\n",
    "             'language':'$language',\n",
    "             'timestamp':'$timestamp',\n",
    "             'text':'$text',\n",
    "             'hashtags':'$hashtags',\n",
    "             'urls':'$urls',\n",
    "             'user_mentions':'$user_mentions',\n",
    "             'geo':'$geo',\n",
    "             'coordinates':'$coordinates',\n",
    "             'retweet_count':'$retweet_count',\n",
    "             'retweeted':'$retweeted',\n",
    "             'is_a_retweet':'$is_a_retweet',\n",
    "             'user_followers':'$user_followers',\n",
    "             'minuto_partita': 'None' ,\n",
    "             'minuto':'None',\n",
    "             'testo':'None',\n",
    "             'squadre':'None',\n",
    "             'soggetti':'None',\n",
    "             'eventi':'None'\n",
    "         }\n",
    "     },\n",
    "       { '$out' :'intervallo'}\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARTITA::\n",
    "agg=db.partita.aggregate(\n",
    "   [{'$match':{\"timestamp\":{\"$lt\":\"2020-08-23 21:01:00\"}}},\n",
    "     {\n",
    "       '$project':\n",
    "         {\n",
    "             'id':'$id',\n",
    "             'user_location':'$user_location',\n",
    "             'language':'$language',\n",
    "             'timestamp':'$timestamp',\n",
    "             'text':'$text',\n",
    "             'hashtags':'$hashtags',\n",
    "             'urls':'$urls',\n",
    "             'user_mentions':'$user_mentions',\n",
    "             'geo':'$geo',\n",
    "             'coordinates':'$coordinates',\n",
    "             'retweet_count':'$retweet_count',\n",
    "             'retweeted':'$retweeted',\n",
    "             'is_a_retweet':'$is_a_retweet',\n",
    "             'user_followers':'$user_followers',\n",
    "             'minuto_partita': 'None',\n",
    "             'minuto':'None',\n",
    "             'testo':'None',\n",
    "             'squadre':'None',\n",
    "             'soggetti':'None',\n",
    "             'eventi':'None'\n",
    "         }\n",
    "     },\n",
    "       { '$out' :'pre_partita'}\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSTPARTITA::\n",
    "agg=db.partita.aggregate(\n",
    "   [{'$match':{\"timestamp\":{\"$gt\":\"2020-08-23 22:54:00\"}}},\n",
    "     {\n",
    "       '$project':\n",
    "         {\n",
    "             'id':'$id',\n",
    "             'user_location':'$user_location',\n",
    "             'language':'$language',\n",
    "             'timestamp':'$timestamp',\n",
    "             'text':'$text',\n",
    "             'hashtags':'$hashtags',\n",
    "             'urls':'$urls',\n",
    "             'user_mentions':'$user_mentions',\n",
    "             'geo':'$geo',\n",
    "             'coordinates':'$coordinates',\n",
    "             'retweet_count':'$retweet_count',\n",
    "             'retweeted':'$retweeted',\n",
    "             'is_a_retweet':'$is_a_retweet',\n",
    "             'user_followers':'$user_followers',\n",
    "             'minuto_partita': 'None', \n",
    "             'minuto':'None',\n",
    "             'testo':'None',\n",
    "             'squadre':'None',\n",
    "             'soggetti':'None',\n",
    "             'eventi':'None'\n",
    "         }\n",
    "     },\n",
    "       { '$out' :'post_partita'}\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ora si convertono in CSV le collezioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#girare json in csv:\n",
    "tweet_df = pd.DataFrame(list(db.primo_tempo.find()))\n",
    "#tweet_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df2 = pd.DataFrame(list(db.secondo_tempo.find()))\n",
    "#tweet_df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importiamo la cronaca\n",
    "racconto=pd.read_csv('/data/my-data/statistiche/FinaleCronaca.csv',encoding='ISO-8859-1')\n",
    "df=pd.DataFrame(racconto)\n",
    "df=df.drop(\"Unnamed: 0\",axis='columns')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo dataset primo e secondo tempo per evityare duplicati sui minuti di recupero e inizio secondo tempo\n",
    "pt=df.loc[1:48]\n",
    "st=df.loc[49:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lavoriamo sul primo tempo separatamente dal secondo tempo:\n",
    "gp_pt=pt.groupby(\"minuto_effettivo\").size().reset_index()\n",
    "un=pd.merge(pt,gp_pt,left_on=\"minuto_effettivo\",right_on=\"minuto_effettivo\",how='left')\n",
    "un_pt=un.rename(columns={un.columns[6]:'count'},inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listone=un_pt.values.tolist() \n",
    "#ottengo una lista di liste dove ogni sottolista √® una riga\n",
    "li_minuto=[]  #creiamo liste vuote che verranno poi compilate e unite come colonne di un dataframe\n",
    "li_minutoeff=[]\n",
    "li_testo=[]\n",
    "li_squadre=[]\n",
    "li_soggetti=[]\n",
    "li_eventi=[]\n",
    "i=0\n",
    "while i<len(listone):\n",
    "    if listone[i][6]!=2:  #count diverso da 2 \n",
    "        li_minuto.append(listone[i][0])\n",
    "        li_minutoeff.append(listone[i][1])\n",
    "        li_testo.append(listone[i][2])\n",
    "        li_squadre.append(listone[i][3])\n",
    "        li_soggetti.append(listone[i][4])\n",
    "        li_eventi.append(listone[i][5])\n",
    "    \n",
    "    elif listone[i][0]==listone[i+1][0]:   #evita 4 count di fila\n",
    "        i+=1 #salta la prima riga e lavora sulla seconda, che avr√† sicuramente un 2 sulla colonna count \n",
    "        #creiamo nuove liste da compilare:\n",
    "        new_testo=[]\n",
    "        new_squadre=[]\n",
    "        new_soggetti=[]\n",
    "        new_eventi=[]\n",
    "        #le compiliamo con i record delle due righe consecutive\n",
    "        new_testo.append(listone[i-1][2]) #prima riga con 2 a count\n",
    "        new_testo.append(listone[i][2]) #seconda riga con 2 a count\n",
    "        new_squadre.append(listone[i-1][3])\n",
    "        new_squadre.append(listone[i][3])\n",
    "        new_soggetti.append(listone[i-1][4])\n",
    "        new_soggetti.append(listone[i][4])\n",
    "        new_eventi.append(listone[i-1][5])\n",
    "        new_eventi.append(listone[i][5])\n",
    "        #compiliamo le colonne finali\n",
    "        li_minuto.append(listone[i][0])  #minuto ed effettivo rerstano gli stessi nelle due liste\n",
    "        li_minutoeff.append(listone[i][1])\n",
    "        li_testo.append(new_testo)\n",
    "        li_squadre.append(new_squadre)\n",
    "        li_soggetti.append(new_soggetti)\n",
    "        li_eventi.append(new_eventi)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "\n",
    "primo=pd.DataFrame({'minuto':li_minuto,'minuto_effettivo':li_minutoeff,'testo':li_testo,'squadre':li_squadre,'soggetti':li_soggetti,'eventi':li_eventi})\n",
    "#primo\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge primo tempo:\n",
    "primoT=pd.merge(tweet_df,primo,left_on='minuto_partita',right_on='minuto_effettivo',how='left')\n",
    "#primoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ora lavoriamo sul secondo tempo\n",
    "gp_st=st.groupby(\"minuto_effettivo\").size().reset_index()\n",
    "un_st=pd.merge(st,gp_st,left_on=\"minuto_effettivo\",right_on=\"minuto_effettivo\",how='left')\n",
    "un_st=un_st.rename(columns={un_st.columns[6]:'count'},inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listone_st=un_st.values.tolist() \n",
    "#ottengo un alista di listedove ogni sottolista √® una riga\n",
    "li_minuto=[]  #creiamo liste vuote che verranno poi compilate e unite come colonne di un dataframe\n",
    "li_minutoeff=[]\n",
    "li_testo=[]\n",
    "li_squadre=[]\n",
    "li_soggetti=[]\n",
    "li_eventi=[]\n",
    "i=0\n",
    "while i<len(listone_st):\n",
    "    if listone_st[i][6]!=2:  #count diverso da 2 \n",
    "        li_minuto.append(listone_st[i][0])\n",
    "        li_minutoeff.append(listone_st[i][1])\n",
    "        li_testo.append(listone_st[i][2])\n",
    "        li_squadre.append(listone_st[i][3])\n",
    "        li_soggetti.append(listone_st[i][4])\n",
    "        li_eventi.append(listone_st[i][5])\n",
    "    \n",
    "    elif listone_st[i][0]==listone_st[i+1][0]:   #evita 4 count di fila\n",
    "        i+=1 #salta la prima riga e lavora sulla seconda, che avr√† sicuramente un 2 sulla colonna count \n",
    "        #creiamo nuove liste da compilare:\n",
    "        new_testo=[]\n",
    "        new_squadre=[]\n",
    "        new_soggetti=[]\n",
    "        new_eventi=[]\n",
    "        #le compiliamo con i record delle due righe consecutive\n",
    "        new_testo.append(listone_st[i-1][2]) #prima riga con 2 a count\n",
    "        new_testo.append(listone_st[i][2]) #seconda riga con 2 a count\n",
    "        new_squadre.append(listone_st[i-1][3])\n",
    "        new_squadre.append(listone_st[i][3])\n",
    "        new_soggetti.append(listone_st[i-1][4])\n",
    "        new_soggetti.append(listone_st[i][4])\n",
    "        new_eventi.append(listone_st[i-1][5])\n",
    "        new_eventi.append(listone_st[i][5])\n",
    "        #compiliamo le colonne finali\n",
    "        li_minuto.append(listone_st[i][0])  #minuto ed effettivo rerstano gli stessi nelle due liste\n",
    "        li_minutoeff.append(listone_st[i][1])\n",
    "        li_testo.append(new_testo)\n",
    "        li_squadre.append(new_squadre)\n",
    "        li_soggetti.append(new_soggetti)\n",
    "        li_eventi.append(new_eventi)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "\n",
    "\n",
    "secondo=pd.DataFrame({'minuto':li_minuto,'minuto_effettivo':li_minutoeff,'testo':li_testo,'squadre':li_squadre,'soggetti':li_soggetti,'eventi':li_eventi})\n",
    "#secondo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondoT=pd.merge(tweet_df2,secondo,left_on='minuto_partita',right_on='minuto_effettivo',how='left')\n",
    "#secondoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>language</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>is_a_retweet</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>minuto_partita</th>\n",
       "      <th>minuto</th>\n",
       "      <th>testo</th>\n",
       "      <th>squadre</th>\n",
       "      <th>soggetti</th>\n",
       "      <th>eventi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5f42bcf1b957f1aa3f1b647e</td>\n",
       "      <td>1297609802558955521</td>\n",
       "      <td>Anywhere Anyway</td>\n",
       "      <td>es</td>\n",
       "      <td>2020-08-23 21:01:00</td>\n",
       "      <td>... Le voy a Neymar y Mbapp√©.... y arranc√≥ el ...</td>\n",
       "      <td>[{'text': 'ChampionsLeague', 'indices': [66, 8...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10217</td>\n",
       "      <td>1</td>\n",
       "      <td>1'</td>\n",
       "      <td>PSG che √É¬® partito determinato attuando un pr...</td>\n",
       "      <td>psg</td>\n",
       "      <td>0</td>\n",
       "      <td>pressing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5f42bcf1b957f1aa3f1b6480</td>\n",
       "      <td>1297609802647048194</td>\n",
       "      <td>None</td>\n",
       "      <td>fr</td>\n",
       "      <td>2020-08-23 21:01:00</td>\n",
       "      <td>RT @Footballogue: [#UCLFinal] PSGüá´üá∑ 0-0 üá©üá™BAYE...</td>\n",
       "      <td>[{'text': 'UCLFinal', 'indices': [19, 28]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Footballogue', 'name': 'Foot...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1619</td>\n",
       "      <td>1</td>\n",
       "      <td>1'</td>\n",
       "      <td>PSG che √É¬® partito determinato attuando un pr...</td>\n",
       "      <td>psg</td>\n",
       "      <td>0</td>\n",
       "      <td>pressing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5f42bcf1b957f1aa3f1b6481</td>\n",
       "      <td>1297609802672222209</td>\n",
       "      <td>ƒ∞stanbul</td>\n",
       "      <td>ca</td>\n",
       "      <td>2020-08-23 21:01:00</td>\n",
       "      <td>RT @SozcuSkor: #UCL finalinde ilk 11'ler:\\n\\nüìå...</td>\n",
       "      <td>[{'text': 'UCL', 'indices': [15, 19]}, {'text'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'SozcuSkor', 'name': 'SKOR', ...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2510622</td>\n",
       "      <td>1</td>\n",
       "      <td>1'</td>\n",
       "      <td>PSG che √É¬® partito determinato attuando un pr...</td>\n",
       "      <td>psg</td>\n",
       "      <td>0</td>\n",
       "      <td>pressing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5f42bcf1b957f1aa3f1b6483</td>\n",
       "      <td>1297609802756116488</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>es</td>\n",
       "      <td>2020-08-23 21:01:00</td>\n",
       "      <td>#UCLfinal en marcha @PSG_espanol @FCBayernES</td>\n",
       "      <td>[{'text': 'UCLfinal', 'indices': [0, 9]}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'PSG_espanol', 'name': 'Paris...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3531</td>\n",
       "      <td>1</td>\n",
       "      <td>1'</td>\n",
       "      <td>PSG che √É¬® partito determinato attuando un pr...</td>\n",
       "      <td>psg</td>\n",
       "      <td>0</td>\n",
       "      <td>pressing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5f42bcf1b957f1aa3f1b6484</td>\n",
       "      <td>1297609802793865217</td>\n",
       "      <td>Europe</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-08-23 21:01:00</td>\n",
       "      <td>Lets goo @FCBayernEN   #ChampionsLeague #UCLFi...</td>\n",
       "      <td>[{'text': 'ChampionsLeague', 'indices': [23, 3...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'FCBayernEN', 'name': 'FC Bay...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1347</td>\n",
       "      <td>1</td>\n",
       "      <td>1'</td>\n",
       "      <td>PSG che √É¬® partito determinato attuando un pr...</td>\n",
       "      <td>psg</td>\n",
       "      <td>0</td>\n",
       "      <td>pressing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id            user_location  \\\n",
       "0  5f42bcf1b957f1aa3f1b647e  1297609802558955521          Anywhere Anyway   \n",
       "1  5f42bcf1b957f1aa3f1b6480  1297609802647048194                     None   \n",
       "2  5f42bcf1b957f1aa3f1b6481  1297609802672222209                 ƒ∞stanbul   \n",
       "3  5f42bcf1b957f1aa3f1b6483  1297609802756116488  Buenos Aires, Argentina   \n",
       "4  5f42bcf1b957f1aa3f1b6484  1297609802793865217                  Europe    \n",
       "\n",
       "  language            timestamp  \\\n",
       "0       es  2020-08-23 21:01:00   \n",
       "1       fr  2020-08-23 21:01:00   \n",
       "2       ca  2020-08-23 21:01:00   \n",
       "3       es  2020-08-23 21:01:00   \n",
       "4       en  2020-08-23 21:01:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  ... Le voy a Neymar y Mbapp√©.... y arranc√≥ el ...   \n",
       "1  RT @Footballogue: [#UCLFinal] PSGüá´üá∑ 0-0 üá©üá™BAYE...   \n",
       "2  RT @SozcuSkor: #UCL finalinde ilk 11'ler:\\n\\nüìå...   \n",
       "3       #UCLfinal en marcha @PSG_espanol @FCBayernES   \n",
       "4  Lets goo @FCBayernEN   #ChampionsLeague #UCLFi...   \n",
       "\n",
       "                                            hashtags urls  \\\n",
       "0  [{'text': 'ChampionsLeague', 'indices': [66, 8...   []   \n",
       "1        [{'text': 'UCLFinal', 'indices': [19, 28]}]   []   \n",
       "2  [{'text': 'UCL', 'indices': [15, 19]}, {'text'...   []   \n",
       "3          [{'text': 'UCLfinal', 'indices': [0, 9]}]   []   \n",
       "4  [{'text': 'ChampionsLeague', 'indices': [23, 3...   []   \n",
       "\n",
       "                                       user_mentions   geo  ... retweet_count  \\\n",
       "0                                                 []  None  ...             0   \n",
       "1  [{'screen_name': 'Footballogue', 'name': 'Foot...  None  ...             0   \n",
       "2  [{'screen_name': 'SozcuSkor', 'name': 'SKOR', ...  None  ...             0   \n",
       "3  [{'screen_name': 'PSG_espanol', 'name': 'Paris...  None  ...             0   \n",
       "4  [{'screen_name': 'FCBayernEN', 'name': 'FC Bay...  None  ...             0   \n",
       "\n",
       "   retweeted  is_a_retweet user_followers  minuto_partita  minuto  \\\n",
       "0      False         False          10217               1      1'   \n",
       "1      False          True           1619               1      1'   \n",
       "2      False          True        2510622               1      1'   \n",
       "3      False         False           3531               1      1'   \n",
       "4      False         False           1347               1      1'   \n",
       "\n",
       "                                               testo squadre soggetti  \\\n",
       "0   PSG che √É¬® partito determinato attuando un pr...     psg        0   \n",
       "1   PSG che √É¬® partito determinato attuando un pr...     psg        0   \n",
       "2   PSG che √É¬® partito determinato attuando un pr...     psg        0   \n",
       "3   PSG che √É¬® partito determinato attuando un pr...     psg        0   \n",
       "4   PSG che √É¬® partito determinato attuando un pr...     psg        0   \n",
       "\n",
       "     eventi  \n",
       "0  pressing  \n",
       "1  pressing  \n",
       "2  pressing  \n",
       "3  pressing  \n",
       "4  pressing  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONCATENIAMO I DATASET DI PRIMO E SECONDO TEMPO:\n",
    "match=pd.concat([primoT,secondoT]).reset_index()\n",
    "match=match.drop([\"index\",\"minuto_effettivo\"],axis=\"columns\")\n",
    "match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hashtags: \n",
    "hastag=match[\"hashtags\"].values.tolist()\n",
    "hashtags=[]\n",
    "for li in hastag:\n",
    "    aus=[]\n",
    "    for diz in li:\n",
    "        aus.append(diz['text'])\n",
    "    hashtags.append(aus)\n",
    "hashtags #unire a dataset ed eliminare \n",
    "match[\"hashtags\"]=hashtags   #sovrascritta\n",
    "#match[\"hashtags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usermentions:  #teniamo screen name e id \n",
    "usermentions=match[\"user_mentions\"].values.tolist()\n",
    "for li in usermentions:\n",
    "    for diz in li:\n",
    "        del diz['id_str']\n",
    "        del diz['indices']\n",
    "        del diz['name']\n",
    "match[\"user_mentions\"]=usermentions\n",
    "#match[\"user_mentions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "urls=match[\"urls\"].values.tolist()\n",
    "for li in urls:\n",
    "    for diz in li:\n",
    "        del diz['indices']\n",
    "match[\"urls\"]=urls\n",
    "#match[\"urls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.to_csv(\"match\",sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo il file integrato con intervallo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING PER LE ALTRE COLLEZIONI:        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intervallo:\n",
    "tweet_int = pd.DataFrame(list(db.intervallo.find()))\n",
    "#hashtags: \n",
    "hastag=tweet_int[\"hashtags\"].values.tolist()\n",
    "hashtags=[]\n",
    "for li in hastag:\n",
    "    aus=[]\n",
    "    for diz in li:\n",
    "        aus.append(diz['text'])\n",
    "    hashtags.append(aus)\n",
    "#hashtags #unire a dataset ed eliminare \n",
    "tweet_int[\"hashtags\"]=hashtags   #sovrascritta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usermentions:  #teniamo screen name e id \n",
    "usermentions=tweet_int[\"user_mentions\"].values.tolist()\n",
    "for li in usermentions:\n",
    "    for diz in li:\n",
    "        del diz['id_str']\n",
    "        del diz['indices']\n",
    "        del diz['name']\n",
    "tweet_int[\"user_mentions\"]=usermentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "urls=tweet_int[\"urls\"].values.tolist()\n",
    "for li in urls:\n",
    "    for diz in li:\n",
    "        del diz['indices']\n",
    "tweet_int[\"urls\"]=urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_stack = pd.concat([match, tweet_int], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_int = vertical_stack.sort_values(by='timestamp',ascending=True)\n",
    "#match_int.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_int.to_csv(\"match_int\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre partita:\n",
    "tweet_pre = pd.DataFrame(list(db.pre_partita.find()))\n",
    "#hashtags: \n",
    "hastag=tweet_pre[\"hashtags\"].values.tolist()\n",
    "hashtags=[]\n",
    "for li in hastag:\n",
    "    aus=[]\n",
    "    for diz in li:\n",
    "        aus.append(diz['text'])\n",
    "    hashtags.append(aus)\n",
    "#hashtags #unire a dataset ed eliminare \n",
    "tweet_pre[\"hashtags\"]=hashtags   #sovrascritta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usermentions:  #teniamo screen name e id \n",
    "usermentions=tweet_pre[\"user_mentions\"].values.tolist()\n",
    "for li in usermentions:\n",
    "    for diz in li:\n",
    "        del diz['id_str']\n",
    "        del diz['indices']\n",
    "        del diz['name']\n",
    "tweet_pre[\"user_mentions\"]=usermentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "urls=tweet_pre[\"urls\"].values.tolist()\n",
    "for li in urls:\n",
    "    for diz in li:\n",
    "        del diz['indices']\n",
    "tweet_pre[\"urls\"]=urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post partita:\n",
    "tweet_post = pd.DataFrame(list(db.post_partita.find()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hashtags: \n",
    "hastag=tweet_post[\"hashtags\"].values.tolist()\n",
    "hashtags=[]\n",
    "for li in hastag:\n",
    "    aus=[]\n",
    "    for diz in li:\n",
    "        aus.append(diz['text'])\n",
    "    hashtags.append(aus)\n",
    "#hashtags #unire a dataset ed eliminare \n",
    "tweet_post[\"hashtags\"]=hashtags   #sovrascritta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usermentions:  #teniamo screen name e id \n",
    "usermentions=tweet_post[\"user_mentions\"].values.tolist()\n",
    "for li in usermentions:\n",
    "    for diz in li:\n",
    "        del diz['id_str']\n",
    "        del diz['indices']\n",
    "        del diz['name']\n",
    "tweet_post[\"user_mentions\"]=usermentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "urls=tweet_post[\"urls\"].values.tolist()\n",
    "for li in urls:\n",
    "    for diz in li:\n",
    "        del diz['indices']\n",
    "tweet_post[\"urls\"]=urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pre.to_csv(\"pre_partita\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_post.to_csv(\"post_partita\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo=pd.concat([pre,match_int,post])\n",
    "completo.drop_duplicates(subset='_id',inplace=True)\n",
    "low_memory=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo.to_csv(\"completo\",sep=\"\\t\",index=False)  #si ottiene il file definitivo sulla partita completa, con pre e post partita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
